{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelCaballero/APD/blob/main/codigo/web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bS66Bi_W3sf"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<td><img src=\"https://raw.githubusercontent.com/RafaelCaballero/APD/refs/heads/main/img/logoAPD.png\" width=\"150\"></td>\n",
        "<td><table><tr><td><h1>Carga de datos desde Web</h1></td></tr>\n",
        "           <tr><td><h3>Rafael Caballero Roldán</h3></td></tr></table></td>\n",
        "<td><img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTsPjCdm67xYS9AM7-dXQ46O23vaexAhnVJaQ&s\" width=\"105\"></td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Un poquito de Web Scraping\n",
        "\n",
        "Cuando los datos no son fáciles de obtener de una página web debemos analizar directemente el código HTML de la práctica. Para esto podemos usar, entre otras, dos bibliotecas:\n",
        "\n",
        "- BeautifulSoup: el estándar para manejar directamente código HTML. Permite navegar por los elementos de la página de forma sencilla\n",
        "- Selenium: cuando la página requiere interactividad, y se quiere automatizar la pulsación de botones, selección de listas desplegables, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PQmxMYyW3sg"
      },
      "outputs": [],
      "source": [
        "modules = [\"numpy\",\"matplotlib\",\"numpy\",\"tqdm\",\"yfinance\", \"html5lib\",\"xlrd\", \"openpyxl\",\"lxml\",\"beautifulsoup4\",\"Selenium\"]\n",
        "\n",
        "import sys\n",
        "import os.path\n",
        "from subprocess import check_call\n",
        "import importlib\n",
        "import os\n",
        "\n",
        "def instala(modules):\n",
        "    print(\"Instalando módulos\")\n",
        "    for m in modules:\n",
        "        # para el import quitamos [...] y ==...\n",
        "        p = m.find(\"[\")\n",
        "        mi = m if p==-1 else m[:p]\n",
        "        p = mi.find(\"==\")\n",
        "        mi = mi if p==-1 else mi[:p]\n",
        "        torch_loader = importlib.util.find_spec(mi)\n",
        "        if torch_loader is not None:\n",
        "            print(m,\" encontrado\")\n",
        "        else:\n",
        "            print(m,\" No encontrado, instalando...\",end=\"\")\n",
        "            try:\n",
        "                r = check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", m])\n",
        "                print(\"¡hecho!\")\n",
        "            except:\n",
        "                print(\"¡Problema al instalar \",m,\"! ¿seguro que el módulo existe?\",sep=\"\")\n",
        "\n",
        "    print(\"¡Terminado!\")\n",
        "\n",
        "instala(modules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGi5-fXSW3sg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = \"https://www.worldometers.info/es/geografia/paises-del-mundo/\"\n",
        "\n",
        "\n",
        "# error, no hay tablas, por eso usamos BeautifulSoup.\n",
        "#dfs = pd.read_html(url)  # error no tables found o forbidden\n",
        "#print(len(dfs))\n",
        "\n",
        "r = requests.get(url)\n",
        "print(\"requests encoding:\", r.encoding, r.apparent_encoding)\n",
        "r.encoding = \"utf-8\"  # lo forzamos\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(r.text, 'html.parser')  # le pasamos el texto en HTML para que lo analice\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHvcBmXpW3sg"
      },
      "source": [
        "El paso anterior ha analizado el texto y extraído sus componentes. Ahora podemos escribir, por ejemplo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb_KxK2RW3sg"
      },
      "outputs": [],
      "source": [
        "print(soup.head.title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8uBeqPCW3sg"
      },
      "outputs": [],
      "source": [
        "print(soup.head.title.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKsziLVjW3sg"
      },
      "source": [
        "Esta forma de \"navegar\" la página de arriba a abajo puede resultar muy tediosa y además solo permite llegar a algunos elementos, es la llamada \"dot navegation\" que usaremos cuando ya estemos cerca de la información que queremos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw2m6ulvW3sh"
      },
      "outputs": [],
      "source": [
        "for e in soup.body.children:\n",
        "    print(e.name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwK07cQOW3sh"
      },
      "source": [
        "Es importante determinar si la información que vemos está en la página descargada; no siempre es así"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm_CID5JW3sh"
      },
      "outputs": [],
      "source": [
        "\"India\" in soup.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlxIWxFLW3sh"
      },
      "source": [
        "Para buscar con más libertad tendremos otras funciones como 'find' y 'find_all' que encuentran, respectivamente, la primera aparición o todas las apariciones de un tag:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hlgC_87W3sh"
      },
      "outputs": [],
      "source": [
        "cabecera = soup.find('h1')\n",
        "cabecera"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3qwyC3HW3sh"
      },
      "outputs": [],
      "source": [
        "cabeceras = soup.find_all('h2')\n",
        "len(cabeceras)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7r_rb0jbW3sh"
      },
      "outputs": [],
      "source": [
        "cabeceras[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDrFoE5xW3sh"
      },
      "source": [
        "Ahora vamos a buscar la información que nos interesa. Tras inspeccionar la página en google Chrome (por ejemplo), vemos que parece que cada fila viene en un elemento de tipo `div` con atributo  class=\"table-row\". La función `select`devuelve todos los elementos que cumplen esto (nótese el . antes del nombre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq9hhSbAW3sh"
      },
      "outputs": [],
      "source": [
        "tables = soup.find_all(\"table\")\n",
        "print(len(tables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrHSpSCKW3sh"
      },
      "outputs": [],
      "source": [
        "tables[0].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OL1zPLOEW3sh"
      },
      "outputs": [],
      "source": [
        "tables[1].text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKkJ7VCdW3sh"
      },
      "outputs": [],
      "source": [
        "table = tables[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rymc808QW3sh"
      },
      "source": [
        "Ahora navegamos a partir de table, eso hace que sea más rápido y más fácil no equivocarse. Recorrido por filas de la tabla"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvJXaKOnW3sh"
      },
      "outputs": [],
      "source": [
        "trs = table.find_all(\"tr\")\n",
        "for tr in trs:\n",
        "    print(tr.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6e3LQTzW3sh"
      },
      "source": [
        "Sobra la primera fila. Además aprovechamos para sacar los componentes tds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wL73sdzeW3sh"
      },
      "outputs": [],
      "source": [
        "trs = table.find_all(\"tr\")\n",
        "for tr in trs[1:]:\n",
        "    tds = tr.find_all(\"td\")\n",
        "    print(len(tds))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xfkZrCqW3sh"
      },
      "outputs": [],
      "source": [
        "trs = table.find_all(\"tr\")\n",
        "lista = []\n",
        "for tr in trs[1:]:\n",
        "    tds = tr.find_all(\"td\")\n",
        "    # posición\n",
        "    fila = [tds[1].text.strip(),int(tds[2].text.strip().replace(\".\",\"\")),tds[3].text.strip()]\n",
        "    lista.append(fila)\n",
        "\n",
        "lista"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTz47vnLW3sh"
      },
      "source": [
        "Convertimos a DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2Mwhw3kW3sh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(lista,columns=[\"Nombre\",\"Habitantes\",\"Continente\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf_kFu8GW3si"
      },
      "outputs": [],
      "source": [
        "df[df.Nombre==\"España\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXzaODX-W3si"
      },
      "source": [
        "Todo junto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwHTFfS_W3si"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.worldometers.info/es/geografia/paises-del-mundo/\"\n",
        "\n",
        "\n",
        "\n",
        "r = requests.get(url)\n",
        "r.encoding = \"utf-8\"  # lo forzamos\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "tables = soup.find_all(\"table\")\n",
        "table = tables[0]\n",
        "\n",
        "trs = table.find_all(\"tr\")\n",
        "lista = []\n",
        "for tr in trs[1:]:\n",
        "    tds = tr.find_all(\"td\")\n",
        "    # posición\n",
        "    fila = [tds[1].text.strip(),int(tds[2].text.strip().replace(\".\",\"\")),tds[3].text.strip()]\n",
        "    lista.append(fila)\n",
        "\n",
        "\n",
        "\n",
        "df.to_csv(\"paises.csv\",index=False)\n",
        "df = pd.DataFrame(lista,columns=[\"Nombre\",\"Habitantes\",\"Continente\"])\n",
        "df\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}